from typing import Any, Callable, Literal, NotRequired, TypedDict

from _typeshed import Incomplete
from pyannote.audio.core.inference import Inference
from pyannote.audio.core.io import AudioFile as AudioFile
from pyannote.audio.core.pipeline import Pipeline
from pyannote.audio.pipelines.utils import PipelineAugmentation as PipelineAugmentation
from pyannote.audio.pipelines.utils import PipelineInference as PipelineInference
from pyannote.audio.pipelines.utils import PipelineModel as PipelineModel
from pyannote.core import Annotation as Annotation
from pyannote.core import SlidingWindowFeature as SlidingWindowFeature
from pyannote.metrics.detection import (
    DetectionErrorRate,
    DetectionPrecisionRecallFMeasure,
)
from torch_audiomentations.core.transforms_interface import (
    BaseWaveformTransform as BaseWaveformTransform,
)

class OracleVoiceActivityDetection(Pipeline):
    @staticmethod
    def apply(file: AudioFile) -> Annotation: ...


Hook = Callable[[str, Any, AudioFile], Any]
Direction = Literal['maximize', 'minimize']


class VadParamsDict(TypedDict):
    onset: float
    offset: float
    min_duration_on: NotRequired[float]
    max_duration_off: NotRequired[float]


class VoiceActivityDetection(Pipeline):
    """Voice activity detection pipeline

    Parameters
    ----------
    segmentation : Model, str, or dict, optional
        Pretrained segmentation (or voice activity detection) model.
        Defaults to "pyannote/segmentation".
        See pyannote.audio.pipelines.utils.get_model for supported format.
    fscore : bool, optional
        Optimize (precision/recall) fscore. Defaults to optimizing detection
        error rate.
    use_auth_token : str, optional
        When loading private huggingface.co models, set `use_auth_token`
        to True or to a string containing your hugginface.co authentication
        token that can be obtained by running `huggingface-cli login`
    inference_kwargs : dict, optional
        Keywords arguments passed to Inference.

    Hyper-parameters
    ----------------
    onset, offset : float
        Onset/offset detection thresholds
    min_duration_on : float
        Remove speech regions shorter than that many seconds.
    min_duration_off : float
        Fill non-speech regions shorter than that many seconds.
    """

    segmentation: PipelineModel
    _segmentation: Inference
    _training: bool
    training: bool

    @staticmethod
    def setup_hook(file: AudioFile, hook: Hook | None = None) -> Hook:
        ...

    def __init__(
        self,
        segmentation: PipelineModel = "pyannote/segmentation",
        fscore: bool = False,
        use_auth_token: str | None = None,
        **inference_kwargs: Any,
    ) -> None:
        ...

    def default_parameters(self) -> VadParamsDict:
        ...

    def classes(self) -> list[Literal['SPEECH']]:
        ...

    def initialize(self) -> None:
        """Initialize pipeline with current set of parameters"""

    CACHED_SEGMENTATION = "cache/segmentation/inference"

    def apply(self, file: AudioFile, hook: Hook | None = None) -> Annotation:
        """Apply voice activity detection

        Parameters
        ----------
        file : AudioFile
            Processed file.
        hook : callable, optional
            Callback called after each major steps of the pipeline as follows:
                hook(step_name,      # human-readable name of current step
                     step_artefact,  # artifact generated by current step
                     file=file)      # file being processed
            Time-consuming steps call `hook` multiple times with the same `step_name`
            and additional `completed` and `total` keyword arguments usable to track
            progress of current step.

        Returns
        -------
        speech : Annotation
            Speech regions.
        """

    def get_metric(self) -> DetectionErrorRate | DetectionPrecisionRecallFMeasure:
        """Return new instance of detection metric"""

    def get_direction(self) -> Direction:
        ...

class AdaptiveVoiceActivityDetection(Pipeline):
    inference: Incomplete
    augmentation: Incomplete
    fscore: Incomplete
    num_epochs: Incomplete
    batch_size: Incomplete
    learning_rate: Incomplete
    def __init__(self, segmentation: PipelineInference = ..., augmentation: PipelineAugmentation = ..., fscore: bool = ...) -> None: ...
    def apply(self, file: AudioFile) -> Annotation: ...
    def get_metric(self) -> DetectionErrorRate | DetectionPrecisionRecallFMeasure: ...
    def get_direction(self) -> Direction: ...
